{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OpenAI library. This library provides a Python interface to the OpenAI API.\n",
    "from openai import OpenAI\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the sample rate and the number of channels\n",
    "sample_rate = 16000\n",
    "channels = 1\n",
    "\n",
    "# Load the model\n",
    "model = Model(\"models/vosk-model-en-us-0.22\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording and transcribing. Press Ctrl+C to stop.\n",
      " A playful golden retriever puppy frolics among vibrant flowers, chasing after a colorful Frisbee in a lush green lawn under a bright blue sky.\n",
      " A sleek black cat bounds gracefully through the garden, batting at butterflies and playfully pouncing on leaves with its dainty paws.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 54\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecording and transcribing. Press Ctrl+C to stop.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[43msd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Schoul\\1CI\\SpeechToImage_Project\\.venv\\Lib\\site-packages\\sounddevice.py:707\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(msec)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msleep\u001b[39m(msec):\n\u001b[0;32m    701\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Put the caller to sleep for at least *msec* milliseconds.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \n\u001b[0;32m    703\u001b[0m \u001b[38;5;124;03m    The function may sleep longer than requested so don't rely on this\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;124;03m    for accurate musical timing.\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \n\u001b[0;32m    706\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m     \u001b[43m_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPa_Sleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create an instance of the OpenAI client. The base_url parameter is set to a local server and the api_key is not needed in this case.\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")\n",
    "\n",
    "# Create a recognizer\n",
    "rec = KaldiRecognizer(model, sample_rate)\n",
    "\n",
    "# Define a global variable to keep track of the recording state\n",
    "global is_recording\n",
    "is_recording = True\n",
    "\n",
    "# Define the conversation history\n",
    "history = [\n",
    "    {\"role\": \"system\", \"content\": \"I'm going to give you an image idea and you are going to return me a creative and enhanced description with keywords of the image you imagine. The description should not be longer than 30 words and be specific and discriptive. Dont be afraid to be creative\"},\n",
    "]\n",
    "\n",
    "# Define a callback function to process the audio chunks\n",
    "def callback(indata, frames, time, status):\n",
    "    global is_recording\n",
    "    if rec.AcceptWaveform(indata.flatten().tobytes()):\n",
    "        result = rec.Result()\n",
    "        result = json.loads(result)\n",
    "        if result.get('text'):  # Only print when there is text\n",
    "            if \"transcription pause\" in result['text']:\n",
    "                is_recording = False\n",
    "            elif \"transcription start\" in result['text']:\n",
    "                is_recording = True\n",
    "                return  # Skip printing the \"transcription start\" command\n",
    "            \n",
    "            if is_recording:\n",
    "                process_user_input(result['text'])\n",
    "\n",
    "# Create a stream to record audio\n",
    "stream = sd.InputStream(callback=callback, channels=channels, samplerate=sample_rate, dtype='int16')\n",
    "\n",
    "def process_user_input(user_input):\n",
    "    # Append user's request to history\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Generate response\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"local-model\", # this field is currently unused\n",
    "        messages=history,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    # Print and append assistant's response to history\n",
    "    print(completion.choices[0].message.content)\n",
    "    history.append({\"role\": \"assistant\", \"content\": completion.choices[0].message.content})\n",
    "\n",
    "\n",
    "# Start recording and processing\n",
    "with stream:\n",
    "    print(\"Recording and transcribing. Press Ctrl+C to stop.\")\n",
    "    while True:\n",
    "        sd.sleep(200)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
